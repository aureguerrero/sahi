{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Detectron2_sahi.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aureguerrero/sahi/blob/main/Detectron2_sahi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LW7vytJ5S3qf"
      },
      "outputs": [],
      "source": [
        "!pip install -U git+https://github.com/aureguerrero/sahi.git\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cpu/torch1.10/index.html # for Detectron2-cpu\n",
        "#!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.10/index.html # for Detectron2-cuda11.1\n",
        "\n",
        "exit(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "buffer='n' #y/n"
      ],
      "metadata": {
        "id": "N_ap2tEAp88i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WACWXxs-YMZy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.getcwd()\n",
        "# will be used for detectron2 fasterrcnn model zoo name\n",
        "from sahi.utils.detectron2 import Detectron2TestConstants\n",
        "\n",
        "# import required functions, classes\n",
        "from sahi.model import Detectron2DetectionModel\n",
        "from sahi.predict import get_sliced_prediction, predict, get_prediction\n",
        "from sahi.utils.file import download_from_url\n",
        "from sahi.utils.cv import read_image\n",
        "from IPython.display import Image\n",
        "import numpy as np\n",
        "!pip install rasterio\n",
        "!pip install affine\n",
        "!pip install pyproj\n",
        "!pip install pygeoj\n",
        "!pip install geopandas\n",
        "import gdal\n",
        "import rasterio\n",
        "from affine import Affine\n",
        "from pyproj import Proj, transform\n",
        "import pygeoj\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import shutil\n",
        "import json\n",
        "import pickle\n",
        "\n",
        "# set detectron2 fasterrcnn model zoo name\n",
        "model_path = Detectron2TestConstants.FASTERCNN_MODEL_ZOO_NAME\n",
        "\n",
        "# download test images into demo_data folder\n",
        "\n",
        "\n",
        "\n",
        "detection_model = Detectron2DetectionModel(\n",
        "    model_path=model_path,\n",
        "    config_path=model_path,\n",
        "    confidence_threshold=0.7,\n",
        "    image_size=640,\n",
        "    device=\"cpu\", # or 'cuda:0'\n",
        "    category_mapping={'0':'planta'},\n",
        ")\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "if buffer =='y':\n",
        "  %cd /content/drive/Shareddrives/Conteo de plantas/SEMANTICA/MAIZ/CON BUFFER 1 cm/pesos\n",
        "else:\n",
        "  %cd /content/drive/Shareddrives/Conteo de plantas/SEMANTICA/MAIZ/SIN BUFFER/pesos\n",
        "\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2 import model_zoo\n",
        "\n",
        "cfg = get_cfg()\n",
        "#cfg.merge_from_file(os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\"))\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"planta_train\",)\n",
        "cfg.DATASETS.TEST = ()#(\"planta_val\",)\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = (os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\"))\n",
        "#cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
        "cfg.SOLVER.MAX_ITER = 1000    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
        "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
        "cfg.MODEL.DEVICE='cpu'\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset (default: 512)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
        "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
        "\n",
        "# Inference should use the config with parameters that are used in training\n",
        "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.6   # set a custom testing threshold\n",
        "predictor = DefaultPredictor(cfg)\n",
        "detection_model.model=predictor\n",
        "%cd /\n",
        "%cd content/\n",
        "%mkdir images/\n",
        "%mkdir resultado/\n",
        "\n",
        "\n",
        "def rotate_bound(image, angle):\n",
        "    # grab the dimensions of the image and then determine the\n",
        "    # center\n",
        "    (h, w) = image.shape[:2]\n",
        "    (cX, cY) = (w // 2, h // 2)\n",
        "\n",
        "    # grab the rotation matrix (applying the negative of the\n",
        "    # angle to rotate clockwise), then grab the sine and cosine\n",
        "    # (i.e., the rotation components of the matrix)\n",
        "    M = cv2.getRotationMatrix2D((cX, cY), -angle, 1.0)\n",
        "    cos = np.abs(M[0, 0])\n",
        "    sin = np.abs(M[0, 1])\n",
        "\n",
        "    # compute the new bounding dimensions of the image\n",
        "    nW = int((h * sin) + (w * cos))\n",
        "    nH = int((h * cos) + (w * sin))\n",
        "\n",
        "    # adjust the rotation matrix to take into account translation\n",
        "    M[0, 2] += (nW / 2) - cX\n",
        "    M[1, 2] += (nH / 2) - cY\n",
        "\n",
        "    # perform the actual rotation and return the image\n",
        "    return cv2.warpAffine(image, M, (nW, nH))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#transformar un np.array a tiff\n",
        "import sys\n",
        "\n",
        "from osgeo import gdal\n",
        "from osgeo import osr\n",
        "import gdal, osr\n",
        "\n",
        "#======================================================================================\n",
        "\n",
        "def createTifFromArray(outputFileName,image,geoTransform,EPSG):\n",
        "    ''' Converts a JPG into a GeoTiff file\n",
        "\n",
        "    Arguments:\n",
        "    outputFileName -- The name of the output GeoTiff\n",
        "    image -- Uint8 array\n",
        "    GeoTransform -- GeoTiff geoparametees, example [ULx,res,0,ULy,0,-resolucion]\n",
        "    EPSG -- GeoTiff EPSG projection, examples: 4326 ; 32720 \n",
        "\n",
        "    Does not return anything.\n",
        "    '''\n",
        "    \n",
        "    heigth,width,bands = image.shape\n",
        "\n",
        "    tipo = gdal.GDT_Byte\n",
        "\n",
        "    driver = gdal.GetDriverByName('GTiff')\n",
        "    dst_ds = driver.Create(outputFileName,width,heigth, bands, tipo)\n",
        "    dst_ds.SetGeoTransform(geoTransform)\n",
        " \n",
        "    srs = osr.SpatialReference()\n",
        "    srs.ImportFromEPSG(EPSG)\n",
        "    dst_ds.SetProjection( srs.ExportToWkt() )\n",
        "\n",
        "    for i in range(bands):\n",
        "        dst_ds.GetRasterBand(i+1).WriteArray(image[:,:,i])\n",
        "\n",
        "    dst_ds = None\n"
      ],
      "metadata": {
        "id": "UAjVInJZCnuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qodRHC038ixL"
      },
      "outputs": [],
      "source": [
        "ancho_ventana=512\n",
        "alto_ventana=512\n",
        "solapamiento_ancho=0.2\n",
        "solapamiento_alto=0.2\n",
        "prob_de_coinc_pospro=0.9\n",
        "detection_model.confidence_threshold=0.7 # nivel de confianza para que muestre un objeto como predicci√≥n\n",
        "centroides=1 # si es None no imprime en imagen los centroides si es 1 imprime centroides\n",
        "d_surco_metros = 52/100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugbvLi2anVoA"
      },
      "outputs": [],
      "source": [
        "for i in os.listdir('images'):\n",
        "  fname = '/content/images/'+i\n",
        "  result= get_sliced_prediction(\n",
        "    fname,\n",
        "    detection_model,\n",
        "    slice_height = alto_ventana,\n",
        "    slice_width = ancho_ventana,\n",
        "    overlap_height_ratio = solapamiento_alto,\n",
        "    overlap_width_ratio = solapamiento_ancho,\n",
        "    postprocess_match_threshold= prob_de_coinc_pospro,\n",
        "    )\n",
        "  result.export_visuals(export_dir='resultado/',export_file='predict_'+i[:-4], etiqueta=1, centro=1, lineas=1)\n",
        "\n",
        "  with open('resultado/predict_'+i[:-4],'wb') as planta:\n",
        "    pickle.dump(result,planta,protocol=pickle.HIGHEST_PROTOCOL) \n",
        "\n",
        "# Para abrir el archivo con resultados\n",
        "  #  with open('resultado/predict_'+i[:-4],'rb') as planta:\n",
        "  #   result=pickle.load(planta)\n",
        "\n",
        "  # Ver los centroides\n",
        "  # result.centroides()\n",
        "\n",
        "  if i[-3:]=='tif' or i[-4:]=='tiff':\n",
        "    with rasterio.open(fname) as r:\n",
        "      T0 = r.transform  # upper-left pixel corner affine transform\n",
        "      p1 = Proj(r.crs)\n",
        "      A = r.read()\n",
        "    datos={\"type\": \"FeatureCollection\",\"name\": i[:-4]+'_vectorizacion',\"crs\": { \"type\": \"name\", \"properties\": { \"name\": \"urn:ogc:def:crs:\"+r.crs.to_string() } }, \"features\":[]}\n",
        "    centros={\"type\": \"FeatureCollection\",\"name\": i[:-4]+'_vectorizacion',\"crs\": { \"type\": \"name\", \"properties\": { \"name\": \"urn:ogc:def:crs:\"+r.crs.to_string() } }, \"features\":[]}\n",
        "    lineas={\"type\": \"FeatureCollection\",\"name\": i[:-4]+'_lineas',\"crs\": { \"type\": \"name\", \"properties\": { \"name\": \"urn:ogc:def:crs:\"+'EPSG:'+str(32720) } }, \"features\":[]}\n",
        "\n",
        "    id=0\n",
        "    id_rect=0\n",
        "    for obj,c in zip(result.object_prediction_list,result.centroides()):\n",
        "      img=np.uint8(255*obj.mask.bool_mask)\n",
        "      contours, hier = cv2.findContours(rotate_bound(cv2.flip(rotate_bound(img, 90),0),180), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "      cont=np.array(contours).squeeze()\n",
        "      if len(np.shape(cont))==1:\n",
        "        planta=[]\n",
        "        area=0\n",
        "        for arreglo in cont:\n",
        "          if len(arreglo)>2:\n",
        "            arreglo=arreglo.squeeze()\n",
        "            area=area+cv2.contourArea(arreglo)*abs(T0[0]*T0[4])\n",
        "            arreglo=np.append(arreglo,[arreglo[0,:]],axis=0)\n",
        "            arreglo=(arreglo+np.array([obj.bbox.miny,obj.bbox.minx]))*np.array([T0[4],T0[0]])+np.array([T0[5],T0[2]])\n",
        "            arreglo=[[arreglo[i][1],arreglo[i][0]] for i in range(np.shape(arreglo)[0])]\n",
        "            planta.append(arreglo)\n",
        "        datos['features'].append({ \"type\": \"Feature\", \"properties\": { \"CLASS_NAME\": \"planta\", \"AREA\": area },\n",
        "                                  \"geometry\": { \"type\": \"MultiPolygon\", \"coordinates\":[planta]}})\n",
        "\n",
        "      else:\n",
        "        area=cv2.contourArea(cont)*abs(T0[0]*T0[4])\n",
        "        cont=np.append(cont,[cont[0,:]],axis=0)\n",
        "        cont=(cont+np.array([obj.bbox.miny,obj.bbox.minx]))*np.array([T0[4],T0[0]])+np.array([T0[5],T0[2]])\n",
        "        cont=[[cont[i][1],cont[i][0]] for i in range(np.shape(cont)[0])]\n",
        "        datos['features'].append({ \"type\": \"Feature\", \"properties\": { \"CLASS_NAME\": \"planta\", \"AREA\": area },\n",
        "                                  \"geometry\": { \"type\": \"MultiPolygon\", \"coordinates\":[[cont]]}})\n",
        "      centros['features'].append({ \"type\": \"Feature\", \"properties\": {\n",
        "           \"CLASS_NAME\": \"planta\", \"AREA\": area, \"ID\" :id}, \"geometry\": { \n",
        "               \"type\": \"Point\", \"coordinates\":[c[0]*T0[0]+T0[2],c[1]*T0[4]+T0[5]]}})\n",
        "      id=id+1\n",
        "    for rect in result.lineas():\n",
        "      lineas['features'].append({ \"type\": \"Feature\", \"properties\": {\n",
        "           \"CLASS_NAME\": \"linea de siembra\", \"ID\" :id_rect}, \"geometry\": { \n",
        "               \"type\": \"MultiLineString\", \n",
        "               \"coordinates\":[[[T0[2],rect(0)*T0[4]+T0[5]],\n",
        "                               [(result.image_width-1)*T0[0]+T0[2],rect((result.image_width-1))*T0[4]+T0[5]]]]}})\n",
        "      id_rect=id_rect+1\n",
        "    with open('/content/resultado/'+i[:-4]+'_vectorial.geojson', 'w') as fp:\n",
        "      json.dump(datos, fp)\n",
        "    with open('/content/resultado/'+i[:-4]+'_centroides.geojson', 'w') as fp:\n",
        "      json.dump(centros, fp)\n",
        "    with open('/content/resultado/'+i[:-4]+'_lineas.geojson', 'w') as fp:\n",
        "      json.dump(lineas, fp)\n",
        "\n",
        "\n",
        "  if i[-3:]=='jpg' or i[-3:]=='JPG':\n",
        "    info_rast=result.info()\n",
        "    createTifFromArray('/content/resultado/'+i[:-4]+'.tif',np.array(result.image),[688822,d_surco_metros / info_rast['resolucion_orig'],0,6238822,0,-d_surco_metros / info_rast['resolucion_orig'] ],32720)\n",
        "    T0=[d_surco_metros / info_rast['resolucion_orig'],0,688822,0,-d_surco_metros / info_rast['resolucion_orig'],6238822]\n",
        "    \n",
        "    datos={\"type\": \"FeatureCollection\",\"name\": i[:-4]+'_vectorizacion',\"crs\": { \"type\": \"name\", \"properties\": { \"name\": \"urn:ogc:def:crs:\"+'EPSG:'+str(32720) } }, \"features\":[]}\n",
        "    centros={\"type\": \"FeatureCollection\",\"name\": i[:-4]+'_centroides',\"crs\": { \"type\": \"name\", \"properties\": { \"name\": \"urn:ogc:def:crs:\"+'EPSG:'+str(32720) } }, \"features\":[]}\n",
        "    lineas={\"type\": \"FeatureCollection\",\"name\": i[:-4]+'_lineas',\"crs\": { \"type\": \"name\", \"properties\": { \"name\": \"urn:ogc:def:crs:\"+'EPSG:'+str(32720) } }, \"features\":[]}\n",
        "    id=0\n",
        "    id_rect=0\n",
        "    for obj,c in zip(result.object_prediction_list,result.centroides()):\n",
        "      img=np.uint8(255*obj.mask.bool_mask)\n",
        "      contours, hier = cv2.findContours(rotate_bound(cv2.flip(rotate_bound(img, 90),0),180), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "      cont=np.array(contours).squeeze()\n",
        "      if len(np.shape(cont))==1:\n",
        "        planta=[]\n",
        "        area=0\n",
        "        for arreglo in cont:\n",
        "          if len(arreglo)>2:\n",
        "            arreglo=arreglo.squeeze()\n",
        "            area=area+cv2.contourArea(arreglo)*abs(T0[0]*T0[4])\n",
        "            arreglo=np.append(arreglo,[arreglo[0,:]],axis=0)\n",
        "            arreglo=(arreglo+np.array([obj.bbox.miny,obj.bbox.minx]))*np.array([T0[4],T0[0]])+np.array([T0[5],T0[2]])\n",
        "            arreglo=[[arreglo[i][1],arreglo[i][0]] for i in range(np.shape(arreglo)[0])]\n",
        "            planta.append(arreglo)\n",
        "        datos['features'].append({ \"type\": \"Feature\", \"properties\": { \"CLASS_NAME\": \"planta\", \"AREA\": area }\n",
        "                                  , \"geometry\": { \"type\": \"MultiPolygon\", \"coordinates\":[planta]}})\n",
        "\n",
        "      else:\n",
        "        area=cv2.contourArea(cont)*abs(T0[0]*T0[4])\n",
        "        cont=np.append(cont,[cont[0,:]],axis=0)\n",
        "        cont=(cont+np.array([obj.bbox.miny,obj.bbox.minx]))*np.array([T0[4],T0[0]])+np.array([T0[5],T0[2]])\n",
        "        cont=[[cont[i][1],cont[i][0]] for i in range(np.shape(cont)[0])]\n",
        "        datos['features'].append({ \"type\": \"Feature\", \"properties\": {\n",
        "             \"CLASS_NAME\": \"planta\", \"AREA\": area }, \"geometry\": { \"type\": \"MultiPolygon\", \"coordinates\":[[cont]]}})\n",
        "      centros['features'].append({ \"type\": \"Feature\", \"properties\": {\n",
        "           \"CLASS_NAME\": \"planta\", \"AREA\": area, \"ID\" :id}, \"geometry\": { \n",
        "               \"type\": \"Point\", \"coordinates\":[c[0]*T0[0]+T0[2],c[1]*T0[4]+T0[5]]}})\n",
        "      id=id+1\n",
        "    for rect in result.lineas():\n",
        "      lineas['features'].append({ \"type\": \"Feature\", \"properties\": {\n",
        "           \"CLASS_NAME\": \"linea de siembra\", \"ID\" :id_rect}, \"geometry\": { \n",
        "               \"type\": \"MultiLineString\", \n",
        "               \"coordinates\":[[[T0[2],rect(0)*T0[4]+T0[5]],\n",
        "                               [(result.image_width-1)*T0[0]+T0[2],rect((result.image_width-1))*T0[4]+T0[5]]]]}})\n",
        "      id_rect=id_rect+1\n",
        "    with open('/content/resultado/'+i[:-4]+'_vectorial.geojson', 'w') as fp:\n",
        "      json.dump(datos, fp)\n",
        "    with open('/content/resultado/'+i[:-4]+'_centroides.geojson', 'w') as fp:\n",
        "      json.dump(centros, fp)\n",
        "    with open('/content/resultado/'+i[:-4]+'_lineas.geojson', 'w') as fp:\n",
        "      json.dump(lineas, fp)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r resultados.zip resultado/"
      ],
      "metadata": {
        "id": "mX1qE-sFCzSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Para sacar lat y long de un jpg"
      ],
      "metadata": {
        "id": "VuWF6TbwDA5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from osgeo import gdal, ogr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import PIL\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from skimage.morphology import skeletonize\n",
        "from skimage import measure\n",
        "from scipy.ndimage import rotate\n",
        "\n",
        "def getJPGLatLon(imageFile):\n",
        "    ''' Get JPG geodata\n",
        "\n",
        "    Arguments:\n",
        "    image -- Geo tagged JPG\n",
        "    \n",
        "\n",
        "    Return:\n",
        "    lat, lon -- Both in decimal degrees\n",
        "\n",
        "    '''\n",
        "    \n",
        "    img = PIL.Image.open(imageFile)\n",
        "  \n",
        "    fileExif = img._getexif()\n",
        "    position_data = fileExif.get(34853)\n",
        "    \n",
        "    # Saco latitud\n",
        "    if (position_data[1] == 'N'):\n",
        "        latH=1\n",
        "    else:\n",
        "        latH=-1\n",
        "\n",
        "    if len(np.shape(np.array(position_data[2])))==2:\n",
        "      lat = latH* (  (float(position_data[2][0][0])/position_data[2][0][1]) + (float(position_data[2][1][0])/(60*position_data[2][1][1])) +(float(position_data[2][2][0])/(60*60*position_data[2][2][1])) )\n",
        "    elif len(np.shape(np.array(position_data[2])))==1:\n",
        "      lat = latH* (  (float(position_data[2][0])) + (float(position_data[2][1])/60) +(float(position_data[2][2])/60**2) )\n",
        "    # Saco longitud\n",
        "    if (position_data[3] == 'E'):\n",
        "        lonH=1\n",
        "    else:\n",
        "        lonH=-1\n",
        "    if len(np.shape(np.array(position_data[4])))==2:    \n",
        "      lon = lonH* (  (float(position_data[4][0][0])/position_data[4][0][1]) + (float(position_data[4][1][0])/(60*position_data[4][1][1])) +(float(position_data[4][2][0])/(60*60*position_data[4][2][1])) )\n",
        "    elif len(np.shape(np.array(position_data[4])))==1:    \n",
        "      lon = lonH* (  (float(position_data[4][0])) + (float(position_data[4][1])/(60)) +(float(position_data[4][2])/(60*60)) )\n",
        "\n",
        "    return (lat,lon)\n",
        "\n",
        "\n",
        "\n",
        "#======================================================================================\n",
        "\n",
        "def getUtmZoneFromLatLon(lat,lon):\n",
        "    ''' Get EPSG UTM ZONE from Lat Lon\n",
        "\n",
        "    Arguments:\n",
        "    lat -- latitude float\n",
        "    lon -- longitude float\n",
        "\n",
        "    Return:\n",
        "    EPSG  -- integer (ie: 32720 for UTM 20S)\n",
        "\n",
        "    '''\n",
        "    \n",
        "    EPSG=int(32700-np.round((45+lat)/90)*100+np.round((183+lon)/6))\n",
        "\n",
        "    return EPSG"
      ],
      "metadata": {
        "id": "oG7VjSm1C0BU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}